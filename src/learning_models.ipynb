{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of top films to keep in my dataset\n",
    "num_top_films_for_model = 10000\n",
    "#number of movies to get top directors and writers\n",
    "cream_of_the_crop = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"../data/movies.csv\")\n",
    "\n",
    "#getting the top 10000 films of all time\n",
    "movies = movies.sort_values(by=['score'], ascending=False).head(num_top_films_for_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the writers and directors from the top 250 films of all time. \n",
    "#These are the top 1% of Hollywood and they are the only ones that matter\n",
    "best_directors = movies.sort_values(by=['score', 'directors'], ascending=False).head(cream_of_the_crop)['directors'].unique().tolist()\n",
    "best_writers = movies.sort_values(by=['score', 'writers'], ascending=False).head(cream_of_the_crop)['writers'].unique().tolist()\n",
    "\n",
    "#the bottom 99% will do into these replaceable lists\n",
    "replacable_directors = []\n",
    "replacable_writers = []\n",
    "\n",
    "for x in movies['directors']:\n",
    "    if x not in best_directors:\n",
    "        replacable_directors.append(x)\n",
    "        \n",
    "for x in movies['writers']:\n",
    "    if x not in best_directors:\n",
    "        replacable_writers.append(x)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the bottom 99% 's unique ID number with 'unknown'\n",
    "#this will help when getting dummies\n",
    "movies.replace(replacable_directors, 'unknown', inplace=True)\n",
    "movies.replace(replacable_writers, 'unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummies for: genres directors, writers\n",
    "genre_dummies = pd.get_dummies(movies['genres'])\n",
    "director_dummies = pd.get_dummies(movies['directors'])\n",
    "writer_dummies = pd.get_dummies(movies['writers'])\n",
    "\n",
    "frames = [movies['startYear'], genre_dummies, director_dummies, writer_dummies, movies['runtimeMinutes'], movies['averageRating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting DataFrame Ready for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a ready for model df that has only the relavant features and target\n",
    "ready_for_model = pd.concat(frames, axis=1)\n",
    "ready_for_model = ready_for_model.drop(['unknown'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models\n",
    "Imports, TT splits, and functions to output  model RMSEs and baseline RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as sk\n",
    "import sklearn.metrics as sk\n",
    "import sklearn.ensemble as ske\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features are: year, genre dummies, writer/director dummies, runtime\n",
    "X = ready_for_model.drop(['averageRating'], axis=1)\n",
    "#target is: average rating\n",
    "y = ready_for_model['averageRating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to output model RMSEs and baseline RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that does the following:\n",
    "#train test split, fit, and prediction\n",
    "#measures model with rmse\n",
    "#prints model name and rmse\n",
    "def regression_model(X, y, my_model):\n",
    "    model = my_model\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "    rmse = sk.mean_squared_error(y_test,predicted)\n",
    "    return rmse\n",
    "\n",
    "    \n",
    "#java style getter method to get baseline rmse\n",
    "def get_baseline_rmse(df):\n",
    "    set_mean = df['averageRating'].mean()\n",
    "    df['error'] = df['averageRating'] - set_mean\n",
    "    summation = 0\n",
    "    for x in df['error']:\n",
    "        summation += x**2\n",
    "    \n",
    "    return (summation/df['error'].size)**(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression() , GradientBoostingRegressor(), and RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR REGRESSION RMSLE: 1.094594555756381e+18\n",
      "GRADIENT BOOSTING RMSLE: 0.3698177956119973\n",
      "RANDOM FOREST REG. RMSLE: 0.46152614956963933\n",
      "BASELINE RMSLE: 0.7268794428239123\n"
     ]
    }
   ],
   "source": [
    "print(\"LINEAR REGRESSION RMSLE: {}\".format(regression_model(X, y, LinearRegression())))\n",
    "print(\"GRADIENT BOOSTING RMSLE: {}\".format(regression_model(X, y, ske.GradientBoostingRegressor())))\n",
    "print(\"RANDOM FOREST REG. RMSLE: {}\".format(regression_model(X, y, ske.RandomForestRegressor())))\n",
    "print('BASELINE RMSLE: {}'.format(get_baseline_rmse(ready_for_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying different hyperparameters on Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_grid = {'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "                          'max_depth': [2, 4, 6],\n",
    "                          'min_samples_leaf': [1, 2, 5, 10],\n",
    "                          'n_estimators': [500],\n",
    "                          'random_state': [1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 56.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
       "                         'max_depth': [2, 4, 6],\n",
       "                         'min_samples_leaf': [1, 2, 5, 10],\n",
       "                         'n_estimators': [500], 'random_state': [1]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdbr_best_model = GridSearchCV(ske.GradientBoostingRegressor(),\n",
    "                                                           gradient_boosting_grid, verbose=1\n",
    "                                                )\n",
    "\n",
    "gdbr_best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOSTING RMSLE AFTER GRID SEARCH: 0.36502637892354994\n"
     ]
    }
   ],
   "source": [
    "gdbr_best_model.predict(X_test)\n",
    "best_params = gdbr_best_model.best_params_\n",
    "best_model = gdbr_best_model.best_estimator_\n",
    "print(\"GRADIENT BOOSTING RMSLE AFTER GRID SEARCH: {}\".format(regression_model(X, y, best_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE RMSLE: 0.7268794428239123\n",
      "-----------------------------------------------\n",
      "LINEAR REGRESSION RMSLE: 1.094594555756381e+18\n",
      "\n",
      "GRADIENT BOOSTING RMSLE: 0.36979547935642426\n",
      "\n",
      "RANDOM FOREST REG. RMSLE: 0.459659835407462\n",
      "\n",
      "GRADIENT BOOSTING GRID: {'learning_rate': [0.1, 0.05, 0.02, 0.01], 'max_depth': [2, 4, 6], 'min_samples_leaf': [1, 2, 5, 10], 'n_estimators': [500], 'random_state': [1]}\n",
      "\n",
      "BEST PARAMERETS FROM GRID SEARCH: {'learning_rate': 0.02, 'max_depth': 6, 'min_samples_leaf': 2, 'n_estimators': 500, 'random_state': 1}\n",
      "\n",
      "GRADIENT BOOSTING RMSLE AFTER GRID SEARCH: 0.36502637892354994\n"
     ]
    }
   ],
   "source": [
    "print('BASELINE RMSLE: {}'.format(get_baseline_rmse(ready_for_model)))\n",
    "print('-----------------------------------------------')\n",
    "print(\"LINEAR REGRESSION RMSLE: {}\".format(regression_model(X, y, LinearRegression())))\n",
    "print()\n",
    "print(\"GRADIENT BOOSTING RMSLE: {}\".format(regression_model(X, y, ske.GradientBoostingRegressor())))\n",
    "print()\n",
    "print(\"RANDOM FOREST REG. RMSLE: {}\".format(regression_model(X, y, ske.RandomForestRegressor())))\n",
    "print()\n",
    "print(\"GRADIENT BOOSTING GRID: {}\".format(gradient_boosting_grid))\n",
    "print()\n",
    "print(\"BEST PARAMERETS FROM GRID SEARCH: {}\".format(best_params))\n",
    "print()\n",
    "print(\"GRADIENT BOOSTING RMSLE AFTER GRID SEARCH: {}\".format(regression_model(X, y, best_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
